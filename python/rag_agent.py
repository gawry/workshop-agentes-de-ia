"""
RAG Agent implementation for Petrobras Q&A system.
"""
from typing import Dict, List, Any
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain.schema import Document
from config import (
    CHROMA_DB_PATH, 
    TOP_K_RETRIEVAL, 
    get_llm_config,
    validate_config
)

class PetrobrasRAGAgent:
    """RAG Agent for Petrobras financial and administrative questions."""
    
    def __init__(self):
        """Initialize the RAG agent."""
        self.llm = None
        self.vectorstore = None
        self.retriever = None
        self.chain = None
        self._setup()
    
    def _setup(self):
        """Setup the RAG chain components."""
        # Validate configuration
        validate_config()
        
        # Get LLM configuration
        llm_config = get_llm_config()
        
        # Initialize LLM
        if llm_config["provider"] == "openai":
            self.llm = ChatOpenAI(
                openai_api_key=llm_config["api_key"],
                model=llm_config["model"],
                temperature=0.1
            )
        else:
            # For OpenRouter, use OpenAI client with custom base URL
            self.llm = ChatOpenAI(
                openai_api_key=llm_config["api_key"],
                model=llm_config["model"],
                temperature=0.1,
                openai_api_base="https://openrouter.ai/api/v1"
            )
        
        # Initialize embeddings
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=llm_config["api_key"],
            model="text-embedding-3-small"
        )
        
        # Load existing Chroma DB
        self.vectorstore = Chroma(
            persist_directory=str(CHROMA_DB_PATH),
            embedding_function=self.embeddings,
            collection_name="petrobras_docs"
        )
        
        # Create retriever
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": TOP_K_RETRIEVAL}
        )
        
        # Create prompt template with comprehensive system prompt
        system_prompt = """Voc√™ √© um **analista financeiro especializado** trabalhando para an√°lise de relat√≥rios da **Petrobras**.

Seu objetivo √© **analisar e responder perguntas sobre os relat√≥rios financeiros da Petrobras, fornecendo insights baseados exclusivamente nos documentos oficiais dispon√≠veis**.

**Dom√≠nio de conhecimento:**
- Relat√≥rios de Desempenho Financeiro da Petrobras (1T25)
- Relat√≥rio da Administra√ß√£o da Petrobras (2024)
- Demonstra√ß√µes financeiras consolidadas
- Indicadores de performance operacional e financeira
- Estrat√©gia e planos de neg√≥cios da Petrobras
- M√©tricas de ESG e sustentabilidade

**Limita√ß√µes importantes:**
- Voc√™ tem acesso SOMENTE aos relat√≥rios da Petrobras fornecidos no contexto
- Voc√™ N√ÉO tem acesso √† internet ou informa√ß√µes externas sobre a Petrobras
- Suas respostas devem ser baseadas EXCLUSIVAMENTE nos relat√≥rios oficiais recuperados
- N√ÉO forne√ßa conselhos de investimento ou recomenda√ß√µes de compra/venda de a√ß√µes

**PROCESSO OBRIGAT√ìRIO:**
1. **Buscar contexto relevante** - Use o sistema de recupera√ß√£o para encontrar se√ß√µes pertinentes
2. **Analisar contexto recuperado** - Leia CUIDADOSAMENTE todos os trechos recuperados
3. **Construir resposta fundamentada** - Use APENAS informa√ß√£o presente nos relat√≥rios oficiais
4. **Adicionar cita√ß√µes obrigat√≥rias** - TODA afirma√ß√£o factual DEVE ter cita√ß√£o espec√≠fica

**REGRAS DE CITA√á√ÉO:**
- Formato obrigat√≥rio: **[Nome do Relat√≥rio, Se√ß√£o/P√°gina]**
- Cada fato, n√∫mero, m√©trica ou declara√ß√£o DEVE incluir cita√ß√£o da fonte
- Sempre inclua o per√≠odo de refer√™ncia quando dispon√≠vel

**FORMATO DE SA√çDA OBRIGAT√ìRIO:**
**RESPOSTA:**
[Sua resposta completa aqui, com cita√ß√µes inline [Fonte, Local]]

**FONTES:**
- Nome completo do relat√≥rio 1
- Nome completo do relat√≥rio 2

**CONFIAN√áA:** alta|m√©dia|baixa

**LIMITA√á√ïES:** [Se aplic√°vel: o que n√£o p√¥de ser respondido e por qu√™]

**PER√çODO DE REFER√äNCIA:** [Per√≠odo dos dados (ex: 1T25, 2024, etc.)]

**COMPORTAMENTOS PROIBIDOS:**
- NUNCA fabricar informa√ß√£o ou inventar n√∫meros
- NUNCA fornecer conselhos de investimento
- NUNCA omitir cita√ß√µes em afirma√ß√µes factuais
- NUNCA fazer interpreta√ß√µes n√£o fundamentadas

**CONTEXTO DISPON√çVEL:**
{context}

**PERGUNTA:** {question}"""

        self.prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{question}")
        ])
        
        # Create RAG chain
        self.chain = (
            {"context": self.retriever | self._format_docs, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
    
    def _format_docs(self, docs: List[Document]) -> str:
        """Format retrieved documents for the prompt."""
        formatted_docs = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get("source", "unknown")
            content = doc.page_content.strip()
            
            # Map source files to proper report names
            if "relatorio-financeiro" in source:
                report_name = "Relat√≥rio de Desempenho 1T25"
            elif "Relatorio-da-administracao" in source:
                report_name = "Relat√≥rio da Administra√ß√£o 2024"
            else:
                report_name = source
            
            formatted_docs.append(f"**{report_name}**\n{content}")
        return "\n\n".join(formatted_docs)
    
    def query(self, question: str) -> Dict[str, Any]:
        """
        Query the RAG agent with a question.
        
        Args:
            question: The question to ask
            
        Returns:
            Dictionary containing answer, sources, and metadata
        """
        try:
            # Get answer from RAG chain
            answer = self.chain.invoke(question)
            
            # Get retrieved documents for source tracking
            retrieved_docs = self.retriever.get_relevant_documents(question)
            
            # Extract sources with proper report names
            sources = []
            for doc in retrieved_docs:
                source = doc.metadata.get("source", "unknown")
                
                # Map source files to proper report names
                if "relatorio-financeiro" in source:
                    report_name = "Relat√≥rio de Desempenho 1T25"
                elif "Relatorio-da-administracao" in source:
                    report_name = "Relat√≥rio da Administra√ß√£o 2024"
                else:
                    report_name = source
                
                if report_name not in sources:
                    sources.append(report_name)
            
            return {
                "question": question,
                "answer": answer,
                "sources": sources,
                "retrieved_docs": len(retrieved_docs),
                "metadata": {
                    "model": self.llm.model_name if hasattr(self.llm, 'model_name') else "unknown",
                    "retrieval_k": TOP_K_RETRIEVAL
                }
            }
            
        except Exception as e:
            return {
                "question": question,
                "answer": f"Erro ao processar pergunta: {str(e)}",
                "sources": [],
                "retrieved_docs": 0,
                "error": str(e)
            }
    
    def test_queries(self):
        """Test the agent with sample queries."""
        test_questions = [
            "Qual foi o EBITDA Ajustado sem eventos exclusivos no 1T25?",
            "Qual foi a produ√ß√£o total de √≥leo e g√°s no 1T25?",
            "Qual √© a pol√≠tica de remunera√ß√£o aos acionistas?",
            "Qual foi o investimento total em 2024?",
            "Devo comprar a√ß√µes da Petrobras baseado nos resultados do 1T25?"  # Test rejection
        ]
        
        print("üß™ Testing RAG Agent with sample queries...\n")
        
        for question in test_questions:
            print(f"‚ùì {question}")
            result = self.query(question)
            print(f"‚úÖ {result['answer']}")
            print(f"üìö Fontes: {', '.join(result['sources'])}")
            print(f"üìä Documentos recuperados: {result['retrieved_docs']}")
            print("-" * 80)

def main():
    """Main function for testing the RAG agent."""
    print("üöÄ Initializing Petrobras RAG Agent...")
    
    try:
        # Create agent
        agent = PetrobrasRAGAgent()
        print("‚úÖ RAG Agent initialized successfully")
        
        # Test with sample queries
        agent.test_queries()
        
        # Interactive mode
        print("\nüí¨ Interactive mode (type 'quit' to exit):")
        while True:
            question = input("\n‚ùì Sua pergunta: ").strip()
            if question.lower() in ['quit', 'exit', 'sair']:
                break
            
            if question:
                result = agent.query(question)
                print(f"\n‚úÖ {result['answer']}")
                if result['sources']:
                    print(f"üìö Fontes: {', '.join(result['sources'])}")
        
    except Exception as e:
        print(f"‚ùå Error initializing RAG agent: {e}")
        raise

if __name__ == "__main__":
    main()
